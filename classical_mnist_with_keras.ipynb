{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2132e92c-1feb-4eae-b1f4-ada9f257a1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e0b569d-ee01-4de8-a54b-cf2ef2ca633b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A convnet takes as input tensors of shape (image_height, image_width, image_channels)-- not including the batch dimensions. \n",
    "# The dimensions below are formatted for MNIST images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "797d56b2-04dc-4b08-9b18-98acb0d5a821",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(28,28,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d8c7a34-161a-476a-9496-b0fa371ddec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of channels is controlled via filters--(32, 64, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb945574-b618-4a70-8ca1-ee59cf1ba6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Max\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-10 21:25:53.901841: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-12-10 21:25:53.902335: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "#Convolutional layers learn local patterns--in the case of images, patterns found in small 2D windows\n",
    "#of the inputs\n",
    "# CONVNETS have two interesting properties\n",
    "# 1. The patterns that they learn are translation-invariant \n",
    "#    After learning a certain pattern, say in the lower right corner of a pic, a convnet can \n",
    "#    recognize it anywhere, such as the top left corner. A densely connected model would have\n",
    "#    have to learn the pattern anew if it appeared at a new location. This makes convnets\n",
    "#    data efficient when processing images: they need fewer training samples to learn\n",
    "#    representations that have generalization power\n",
    "# 2. They can learn spatial hiearchies of patterns \n",
    "#    A first CNN layer will learn small local patterns such as edges, a second larger patterns\n",
    "#    made of features of the first layers, and so on. Allows CNNs to learn increasingly complex\n",
    "#    and abstract concepts, because the visual worls is fundamentally spatially hiearchial\n",
    "\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "# DENSE layers learn global patterns in their input feature space -- for MNIST this means all pixels\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c59da412-37f8-41bb-8ee9-7a7de2c24e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 128)         73856     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                11530     \n",
      "=================================================================\n",
      "Total params: 104,202\n",
      "Trainable params: 104,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3af6d66d-3245-47a2-b615-e5a6dccfe8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b8df703-0cde-4b1d-a298-4be31b069313",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bec68a8e-b610-448d-acb6-7ac39d13c36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0477fc1f-1714-4e0c-8496-8f49c108469e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e4985f9-e8a3-40ea-98e8-c98b0ca91341",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-10 21:26:08.211484: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-12-10 21:26:08.211651: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2021-12-10 21:26:08.342184: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.1558 - accuracy: 0.9514\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0435 - accuracy: 0.9864\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0296 - accuracy: 0.9903\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0229 - accuracy: 0.9931\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.0178 - accuracy: 0.9950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x292b355b0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be484a05-b59f-4a2b-a033-4a551e69b175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 24/313 [=>............................] - ETA: 1s - loss: 0.0257 - accuracy: 0.9870   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-10 21:27:03.822599: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0242 - accuracy: 0.9914\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1079909d-6a3d-4ca8-9627-b5c1e7bfd248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.991\n"
     ]
    }
   ],
   "source": [
    "print(f'Test accuracy: {test_acc: .3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
